{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import os\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sae.preprocess import get_meta_info,get_freq_emmbeddings, get_tf_idfs_emmbeddings,get_bert_embeddings\n",
    "from sae.models import DEEPmodel_2\n",
    "import time\n",
    "import joblib\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid = pd.read_csv('validation_data.csv')\n",
    "data_valid.rename(columns={'revue/score':'rating',\"revue/résumé\":\"summary\",\"revue/texte\":\"comment\"}, inplace=True)\n",
    "data_valid[\"summary\"] = np.where(pd.isnull(data_valid[\"summary\"]), '', data_valid[\"summary\"])\n",
    "data_valid[\"comment\"] = np.where(pd.isnull(data_valid[\"comment\"]), '', data_valid[\"comment\"])\n",
    "len(data_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cacul des metas attribut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on recharge tous les fichiers json pour verifier\n",
    "with open('titre_info.json', 'r') as fp:\n",
    "    titre_info = json.load(fp)\n",
    "with open('author_data.json', 'r') as fp:\n",
    "    author_data = json.load(fp)\n",
    "with open('genre_data.json', 'r') as fp:\n",
    "    genre_data = json.load(fp)\n",
    "with open('editor_data.json', 'r') as fp:\n",
    "    editor_data = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratings_author, nb_rat_auhtor, ratings_genre, nb_rat_genre, ratings_editor, nb_rat_editor =  get_meta_info(data_valid,titre_info, author_data,genre_data,editor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on rajoute les colonnes dans le dataframe ratings\n",
    "data_valid['auteur_note'] = ratings_author\n",
    "data_valid['auteur_nb'] = nb_rat_auhtor\n",
    "data_valid['genre_note'] = ratings_genre\n",
    "data_valid['genre_nb'] = nb_rat_genre\n",
    "data_valid['editor_note'] = ratings_editor\n",
    "data_valid['editor_nb'] = nb_rat_editor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_meta = data_valid[['auteur_note','auteur_nb','genre_note','genre_nb','editor_note','editor_nb']].values\n",
    "\n",
    "X_meta.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul des embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calcule les embeddings ou utilise les embeddings pre-entrainés\n",
    "mode = \"summary\"\n",
    "#on remplace les nan par des chaines de caractères vides\n",
    "\n",
    "# Load the saved model\n",
    "with open('model_freq_emb.pkl', 'rb') as file:\n",
    "    model_freq = pickle.load(file)\n",
    "X_emb_freq,_ = get_freq_emmbeddings(data_valid[mode].values,model_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_valid_rating = data_valid['rating'].values.astype(int)\n",
    "Y_valid_sentiment = data_valid['rating'].values.astype(int)\n",
    "Y_valid_sentiment[Y_valid_sentiment < 3] = 0\n",
    "Y_valid_sentiment[Y_valid_sentiment == 3] = 1\n",
    "Y_valid_sentiment[Y_valid_sentiment > 3] = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mots simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Freqmodel = joblib.load('freq_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Freq,inutile = get_freq_emmbeddings(list(data_valid[mode].values),model=Freqmodel)\n",
    "X_valid_Freq = np.concatenate((X_meta,X_Freq),axis=1)\n",
    "X_Freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 2 0 2]\n",
      "[2 2 2 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8005"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = joblib.load('freq_gradientboosting.pkl')\n",
    "result=nb_model.predict(X_valid_Freq)\n",
    "print(result)\n",
    "print(Y_valid_sentiment)\n",
    "accuracy_score(result,Y_valid_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_Freq = np.concatenate((X_meta,X_Freq),axis=1)\n",
    "batch_size = 128\n",
    "valid_dataset_Freq_sent = TensorDataset(torch.tensor(X_valid_Freq),torch.tensor(Y_valid_sentiment, dtype=torch.long))\n",
    "valid_loader_Freq_sent = DataLoader(valid_dataset_Freq_sent, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldSimple = DEEPmodel_2(input_size=1006, features = [512,512,512,512,256], sub_features =[256,256], nb_class=3)\n",
    "modeldSimple.load_state_dict(torch.load('Deep_freq.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyh valid : 0.8395\n"
     ]
    }
   ],
   "source": [
    "modeldSimple.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = []\n",
    "    for i, (x, y) in enumerate(valid_loader_Freq_sent):\n",
    "        x = x.float()  \n",
    "        y_pred_batch = modeldSimple(x).argmax(1)\n",
    "        y_pred.append(y_pred_batch)  # Move to CPU for evaluation\n",
    "    \n",
    "    y_pred = torch.cat(y_pred)\n",
    "acc_valid = accuracy_score(Y_valid_sentiment, y_pred.numpy())\n",
    "print(\"accuracyh valid :\", acc_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfmodel = joblib.load('tfidf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_idf,inutile = get_tf_idfs_emmbeddings(list(data_valid[mode].values),model=idfmodel)\n",
    "X_valid_idf = np.concatenate((X_meta,X_idf),axis=1)\n",
    "X_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 2 0 2]\n",
      "[2 2 2 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.801"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le modèle\n",
    "nb_model = joblib.load('idf_gradientboosting.pkl')\n",
    "result=nb_model.predict(X_valid_idf)\n",
    "print(result)\n",
    "print(Y_valid_sentiment)\n",
    "accuracy_score(result,Y_valid_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "valid_dataset_idf_sent = TensorDataset(torch.tensor(X_valid_idf),torch.tensor(Y_valid_sentiment, dtype=torch.long))\n",
    "valid_loader_idf_sent = DataLoader(valid_dataset_idf_sent, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldidf = DEEPmodel_2(input_size=1006, features = [512,512,512,512,256], sub_features =[256,256], nb_class=3)\n",
    "modeldidf.load_state_dict(torch.load('Deep_idf.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyh valid : 0.837\n"
     ]
    }
   ],
   "source": [
    "modeldidf.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = []\n",
    "    for i, (x, y) in enumerate(valid_loader_idf_sent):\n",
    "        x = x.float()  \n",
    "        y_pred_batch = modeldidf(x).argmax(1)\n",
    "        y_pred.append(y_pred_batch)  # Move to CPU for evaluation\n",
    "    \n",
    "    y_pred = torch.cat(y_pred)\n",
    "acc_valid = accuracy_score(Y_valid_sentiment, y_pred.numpy())\n",
    "print(\"accuracyh valid :\", acc_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************\n"
     ]
    }
   ],
   "source": [
    "X_bert = get_bert_embeddings(list(data_valid[mode].values)).numpy()\n",
    "X_valid_bert = np.concatenate((X_meta,X_bert),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 0 0 2]\n",
      "[2 2 2 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8265"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le modèle\n",
    "nb_model = joblib.load('bert_gradientboosting.pkl')\n",
    "result=nb_model.predict(X_valid_bert)\n",
    "print(result)\n",
    "print(Y_valid_sentiment)\n",
    "accuracy_score(result,Y_valid_sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "valid_dataset_bert_sent = TensorDataset(torch.tensor(X_valid_bert),torch.tensor(Y_valid_sentiment, dtype=torch.long))\n",
    "valid_loader_bert_sent = DataLoader(valid_dataset_bert_sent, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DEEPmodel_2(input_size=774, features = [512,512,512,512,256], sub_features =[256,256], nb_class=3)\n",
    "model.load_state_dict(torch.load('Deep_bert.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyh valid : 0.897\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = []\n",
    "    for i, (x, y) in enumerate(valid_loader_bert_sent):\n",
    "        x = x.float()  \n",
    "        y_pred_batch = model(x).argmax(1)\n",
    "        y_pred.append(y_pred_batch)  # Move to CPU for evaluation\n",
    "    \n",
    "    y_pred = torch.cat(y_pred)\n",
    "acc_valid = accuracy_score(Y_valid_sentiment, y_pred.numpy())\n",
    "print(\"accuracyh valid :\", acc_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
